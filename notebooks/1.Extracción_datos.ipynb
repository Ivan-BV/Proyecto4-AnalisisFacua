{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generación del archivo requirements.txt\n",
    "!pip freeze > ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from selenium import webdriver  # Selenium es una herramienta para automatizar la interacción con navegadores web.\n",
    "from webdriver_manager.chrome import ChromeDriverManager  # ChromeDriverManager gestiona la instalación del controlador de Chrome.\n",
    "from selenium.webdriver.support.ui import Select  # Select se utiliza para interactuar con elementos <select> en páginas web.\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException # Excepciones comunes de selenium que nos podemos encontrar\n",
    "import json\n",
    "import sys\n",
    "from datetime import datetime\n",
    "sys.path.append(\"../\")\n",
    "import src.soporte_extraccion as se"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción de URLs con Selenium y Beautiful Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo el driver que utiliza Selenium\n",
    "driver = webdriver.Chrome()\n",
    "\n",
    "# Generó por defecto el tiempo de espera para encontrar el elemento que le pido\n",
    "driver.implicitly_wait(10)\n",
    "\n",
    "# Abro la página de la que vamos a extraer los datos\n",
    "url_facua = \"https://super.facua.org/\"\n",
    "driver.get(url_facua)\n",
    "\n",
    "# Maximizo la página para mostrar todos los elementos. Esto se hace por si tiene responsive y esconde elementos\n",
    "driver.maximize_window()\n",
    "try:\n",
    "    # Hago una pausa para que cargue el html de la página y asegurarme encontrar el elemento que le pido posteriormente\n",
    "    sleep(1)\n",
    "\n",
    "    # Acepto las cookies para que no molesten el resto del scrap\n",
    "    driver.find_element(\"css selector\", \"#rcc-confirm-button\").click()\n",
    "\n",
    "    # Extracción de urls con Selenium\n",
    "    diccionario_urls = se.obtener_lista_url(driver)\n",
    "    print(\"Primera lista de URLs obtenida\")\n",
    "\n",
    "    # Extracción de urls de categorias con Selenium\n",
    "    diccionario_categorias = se.obtener_categorias(diccionario_urls, driver)\n",
    "    print(\"Segunda lista de URLs obtenida\")\n",
    "\n",
    "    # Cierro el driver de Selenium porque ya hemos extraido todo lo necesario\n",
    "    driver.close()\n",
    "    \n",
    "    # Extracción de urls de los productos con Beautiful Soup\n",
    "    diccionario_subcategorias = se.obtener_subcategorias(diccionario_categorias)\n",
    "    print(\"Tercera lista de URLs obtenida\")\n",
    "    print(\"URLs extraidas\")\n",
    "    \n",
    "except NoSuchElementException as error:\n",
    "    # En caso de error muestra este mensaje\n",
    "    print(f\"Error al encontrar el elemento: {error.msg}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo el diccionario creado en un archivo json para no tener que ejecutar de nuevo el código anterior\n",
    "with open('../datos/raw/urls.json', 'w') as jf:\n",
    "    json.dump(diccionario_subcategorias, jf, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compruebo que se ha guardado correctamente el json\n",
    "with open('../datos/raw/urls.json', 'r') as jf: \n",
    "    diccionario_urls2 = json.load(jf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraigo la información de los precios historicos de las tablas con una función asíncrona\n",
    "df_precios_historicos = await se.extraer_informacion(diccionario_urls2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo el dataframe con todos los registros en un csv\n",
    "df_precios_historicos.to_csv(f\"../datos/raw/precios_historicos_{datetime.now().date()}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proyecto4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
